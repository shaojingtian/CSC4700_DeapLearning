{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-69713817bef3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgpu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlogical_gpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_logical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Physical GPUs,\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogical_gpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Logical GPUs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/config.py\u001b[0m in \u001b[0;36mlist_logical_devices\u001b[0;34m(device_type)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mLogicalDevice\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m   \"\"\"\n\u001b[0;32m--> 347\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_logical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/context.py\u001b[0m in \u001b[0;36mlist_logical_devices\u001b[0;34m(self, device_type)\u001b[0m\n\u001b[1;32m   1150\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mlist_logical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0;34m\"\"\"Return logical devices.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[0mdevices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/context.py\u001b[0m in \u001b[0;36mensure_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_is_async\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mASYNC\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m           \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ContextOptionsSetAsync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_NewContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_DeleteContextOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # input\n",
    "    input_shape = x_train.shape\n",
    "    visible = tf.keras.layers.Input(shape=input_shape[1:])\n",
    "    conv_input = tf.keras.layers.Conv2D(32,(3,3),padding='same')(visible)\n",
    "    batchnorm_input = tf.keras.layers.BatchNormalization()(conv_input)\n",
    "    relu_input = tf.keras.layers.ReLU()(batchnorm_input)\n",
    "    \n",
    "    #section A\n",
    "    #A1\n",
    "    ConvA1_1 = tf.keras.layers.Conv2D(32,(3,3),padding='same')(relu_input)\n",
    "    batchnormA1_1 = tf.keras.layers.BatchNormalization()(ConvA1_1)\n",
    "    reluA1_1 = tf.keras.layers.ReLU()(batchnormA1_1)\n",
    "    ConvA1_2 = tf.keras.layers.Conv2D(32,(3,3),padding='same')(reluA1_1)\n",
    "    batchnormA1_2 = tf.keras.layers.BatchNormalization()(ConvA1_2)\n",
    "    addA1 = tf.keras.layers.Add()([batchnormA1_2,relu_input])\n",
    "    reluA1_2 = tf.keras.layers.ReLU()(addA1)\n",
    "    \n",
    "    #A2\n",
    "    ConvA2_1 = tf.keras.layers.Conv2D(32,(3,3),padding='same')(reluA1_2)\n",
    "    batchnormA2_1 = tf.keras.layers.BatchNormalization()(ConvA2_1)\n",
    "    reluA2_1 = tf.keras.layers.ReLU()(batchnormA2_1)\n",
    "    ConvA2_2 = tf.keras.layers.Conv2D(32,(3,3),padding='same')(reluA2_1)\n",
    "    batchnormA2_2 = tf.keras.layers.BatchNormalization()(ConvA2_2)\n",
    "    addA2 = tf.keras.layers.Add()([batchnormA2_2,reluA1_2])\n",
    "    reluA2_2 = tf.keras.layers.ReLU()(addA2)\n",
    "    \n",
    "    #A3\n",
    "    ConvA3_1 = tf.keras.layers.Conv2D(32,(3,3),padding='same')(reluA2_2)\n",
    "    batchnormA3_1 = tf.keras.layers.BatchNormalization()(ConvA3_1)\n",
    "    reluA3_1 = tf.keras.layers.ReLU()(batchnormA3_1)\n",
    "    ConvA3_2 = tf.keras.layers.Conv2D(32,(3,3),padding='same')(reluA3_1)\n",
    "    batchnormA3_2 = tf.keras.layers.BatchNormalization()(ConvA3_2)\n",
    "    addA3 = tf.keras.layers.Add()([batchnormA3_2,reluA2_2])\n",
    "    reluA3_2 = tf.keras.layers.ReLU()(addA3)\n",
    "    \n",
    "    #section B\n",
    "    #B1\n",
    "    ConvB1_1 = tf.keras.layers.Conv2D(64,(3,3),strides=(2,2),padding='same')(reluA3_2)\n",
    "    batchnormB1_1 = tf.keras.layers.BatchNormalization()(ConvB1_1)\n",
    "    reluB1_1 = tf.keras.layers.ReLU()(batchnormB1_1)\n",
    "    ConvB1_2 = tf.keras.layers.Conv2D(64,(3,3),padding='same')(reluB1_1)\n",
    "    batchnormB1_2 = tf.keras.layers.BatchNormalization()(ConvB1_2)\n",
    "    skiptensorB1 = tf.keras.layers.Conv2D(64,(1,1),strides=(2,2),padding='same')(reluA3_2)\n",
    "    addB1 = tf.keras.layers.Add()([batchnormB1_2,skiptensorB1])\n",
    "    reluB1_2 = tf.keras.layers.ReLU()(addB1)\n",
    "    \n",
    "    #B2\n",
    "    ConvB2_1 = tf.keras.layers.Conv2D(64,(3,3),padding='same')(reluB1_2)\n",
    "    batchnormB2_1 = tf.keras.layers.BatchNormalization()(ConvB2_1)\n",
    "    reluB2_1 = tf.keras.layers.ReLU()(batchnormB2_1)\n",
    "    ConvB2_2 = tf.keras.layers.Conv2D(64,(3,3),padding='same')(reluB2_1)\n",
    "    batchnormB2_2 = tf.keras.layers.BatchNormalization()(ConvB2_2)\n",
    "    addB2 = tf.keras.layers.Add()([batchnormB2_2,reluB1_2])\n",
    "    reluB2_2 = tf.keras.layers.ReLU()(addB2)\n",
    "    \n",
    "    #B3\n",
    "    ConvB3_1 = tf.keras.layers.Conv2D(64,(3,3),padding='same')(reluB2_2)\n",
    "    batchnormB3_1 = tf.keras.layers.BatchNormalization()(ConvB3_1)\n",
    "    reluB3_1 = tf.keras.layers.ReLU()(batchnormB3_1)\n",
    "    ConvB3_2 = tf.keras.layers.Conv2D(64,(3,3),padding='same')(reluB3_1)\n",
    "    batchnormB3_2 = tf.keras.layers.BatchNormalization()(ConvB3_2)\n",
    "    addB3 = tf.keras.layers.Add()([batchnormB3_2,reluB2_2])\n",
    "    reluB3_2 = tf.keras.layers.ReLU()(addB3)\n",
    "    \n",
    "    #section C\n",
    "    #C1\n",
    "    ConvC1_1 = tf.keras.layers.Conv2D(128,(3,3),strides=(2,2),padding='same')(reluB3_2)\n",
    "    batchnormC1_1 = tf.keras.layers.BatchNormalization()(ConvC1_1)\n",
    "    reluC1_1 = tf.keras.layers.ReLU()(batchnormC1_1)\n",
    "    ConvC1_2 = tf.keras.layers.Conv2D(128,(3,3),padding='same')(reluC1_1)\n",
    "    batchnormC1_2 = tf.keras.layers.BatchNormalization()(ConvC1_2)\n",
    "    skiptensorC1 = tf.keras.layers.Conv2D(128,(1,1),strides=(2,2),padding='same')(reluB3_2)\n",
    "    addC1 = tf.keras.layers.Add()([batchnormC1_2,skiptensorC1])\n",
    "    reluC1_2 = tf.keras.layers.ReLU()(addC1)\n",
    "    \n",
    "    #C2\n",
    "    ConvC2_1 = tf.keras.layers.Conv2D(128,(3,3),padding='same')(reluC1_2)\n",
    "    batchnormC2_1 = tf.keras.layers.BatchNormalization()(ConvC2_1)\n",
    "    reluC2_1 = tf.keras.layers.ReLU()(batchnormC2_1)\n",
    "    ConvC2_2 = tf.keras.layers.Conv2D(128,(3,3),padding='same')(reluC2_1)\n",
    "    batchnormC2_2 = tf.keras.layers.BatchNormalization()(ConvC2_2)\n",
    "    addC2 = tf.keras.layers.Add()([batchnormC2_2,reluC1_2])\n",
    "    reluC2_2 = tf.keras.layers.ReLU()(addC2)\n",
    "    \n",
    "    #C3\n",
    "    ConvC3_1 = tf.keras.layers.Conv2D(128,(3,3),padding='same')(reluC2_2)\n",
    "    batchnormC3_1 = tf.keras.layers.BatchNormalization()(ConvC3_1)\n",
    "    reluC3_1 = tf.keras.layers.ReLU()(batchnormC3_1)\n",
    "    ConvC3_2 = tf.keras.layers.Conv2D(128,(3,3),padding='same')(reluC3_1)\n",
    "    batchnormC3_2 = tf.keras.layers.BatchNormalization()(ConvC3_2)\n",
    "    addC3 = tf.keras.layers.Add()([batchnormC3_2,reluC2_2])\n",
    "    reluC3_2 = tf.keras.layers.ReLU()(addC3)\n",
    "    \n",
    "    #global_average_pooling\n",
    "    pooling = tf.keras.layers.GlobalAveragePooling2D()(reluC3_2)\n",
    "    \n",
    "    #flatten\n",
    "    flat = tf.keras.layers.Flatten()(pooling)\n",
    "    \n",
    "    #dense\n",
    "    output = tf.keras.layers.Dense(10,activation='softmax')(flat)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=visible, outputs=output)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = create_model()\n",
    "model_1.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model_1.fit(x_train,y_train, epochs=50, batch_size=500)\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test,verbose=2)\n",
    "print(val_loss,val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
